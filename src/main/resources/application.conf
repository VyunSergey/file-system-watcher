path = "F:/temp/products/data"
product-mask = "^.*/products/data/product.*[0-9]+$"
transfer-file-mask = "kvd_<NUM>.csv"
transfer-archive = "kvd.zip"
transfer-marker = "kvd.zip.done"
csv-mask = "^.*\\.csv$"
zip-mask = "^.*\\.zip$"
file-mask = {
  "csv" : {
    data-file   = "^.*/in/.*\\.csv$"
    marker-file = "^.*/in/.*\\.csv\\.done$"
  }
  "zip" : {
    data-file   = "^.*/in/.*\\.zip$"
    marker-file = "^.*/in/.*\\.zip\\.done$"
  }
  "spark-meta" : {
    data-file   = "^.*/meta/.*\\.csv$"
    marker-file = "^.*/meta/_SUCCESS$"
  }
  "spark-data" : {
    data-file   = "^.*/data/.*\\.csv$"
    marker-file = "^.*/data/_SUCCESS$"
  }
  "transfer" : {
    data-file   = "^.*/transfer/.*\\.zip$"
    marker-file = "^.*/transfer/.*\\.zip\\.done$"
  }
}
transformer = {
  mode = "csv"
  max-file-size = 104857600
  product-path = "F:/temp/products/conf"
  jar-path = "F:/Stash/spark-excel-csv-loader/target/scala-2.11/spark-excel-csv-loader-2.11.12_0.1.jar"
  command = "java -Xss1G -Xms2G -Xmx6G <OPTIONS> -jar <JAR_PATH> --mode=<MODE> --num-parts=<NUM_PARTS> --src-path=<SRC_PATH> --tgt-path=<TGT_PATH>"
  options = {
    spark = {
      spark = [
        "spark.master='local[*]'"
      ]
    }
    writer = {
      save-mode = "Overwrite"
      encoding = "UTF-8"
      header = "true"
      delimiter = ","
    }
  }
}
